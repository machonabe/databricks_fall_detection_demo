{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ad70d36-ccda-4476-a1c9-baf238ac9735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------#\n",
    "# 1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æº–å‚™\n",
    "# Databricks Runtime 14.x ä»¥é™æ¨å¥¨\n",
    "%pip install --upgrade databricks-langchain databricks-vectorsearch mlflow langgraph pillow sentence-transformers\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b37e781f-216d-4774-8196-e3f4aa4bbf24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "import os\n",
    "import tempfile\n",
    "import mlflow\n",
    "import json\n",
    "import numpy as np\n",
    "import warnings\n",
    "import uuid\n",
    "from typing import List, Any, Generator, Optional, Sequence, Union\n",
    "\n",
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    VectorSearchRetrieverTool,\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "# sentence-transformers ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆè­¦å‘Šã‚’æŠ‘åˆ¶ï¼‰\n",
    "warnings.filterwarnings(\"ignore\", message=\".*use_fast.*\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "print(\"âœ… ã™ã¹ã¦ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæ­£å¸¸ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã•ã‚Œã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d7c75e2-f547-4c9d-84a1-6e1c0b2bd80e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# å®šæ•°å®šç¾©\n",
    "\n",
    "# Widgetsã®ä½œæˆ\n",
    "dbutils.widgets.text(\"catalog\", \"fall_detection_demo_catalog\", \"ã‚«ã‚¿ãƒ­ã‚°\")\n",
    "dbutils.widgets.text(\"schema\", \"{ã”è‡ªèº«ã®ã‚¹ã‚­ãƒ¼ãƒåã‚’å…¥åŠ›}\", \"ã‚¹ã‚­ãƒ¼ãƒ\")\n",
    "dbutils.widgets.text(\"suffix\", \"{ã”è‡ªèº«ã®Suffixã‚’æŒ‡å®š}\", \"ENDPOINTç”¨ã®æ¥å°¾è¾\")\n",
    "dbutils.widgets.dropdown(\"recreate_schema\", \"False\", [\"True\", \"False\"], \"ã‚¹ã‚­ãƒ¼ãƒã‚’å†ä½œæˆ\")\n",
    "\n",
    "\n",
    "# Widgetã‹ã‚‰ã®å€¤ã®å–å¾—\n",
    "CATALOG = dbutils.widgets.get(\"catalog\")\n",
    "SCHEMA = dbutils.widgets.get(\"schema\")\n",
    "RECREATE_SCHEMA = dbutils.widgets.get(\"recreate_schema\") == \"True\"\n",
    "SUFFIX = dbutils.widgets.get(\"suffix\")\n",
    "\n",
    "# Volume ãƒ‘ã‚¹å®šç¾©\n",
    "VIDEO_VOL = f\"/Volumes/{CATALOG}/{SCHEMA}/video_volume\"\n",
    "FRAME_VOL = f\"/Volumes/{CATALOG}/{SCHEMA}/frame_volume\"\n",
    "\n",
    "INDEX_NAME = f\"{CATALOG}.{SCHEMA}.fall_detection_index\"\n",
    "\n",
    "VS_ENDPOINT = f\"fall_detection_vector_search_{SUFFIX}\"\n",
    "LLM_ENDPOINT = \"databricks-claude-3-7-sonnet\"\n",
    "\n",
    "\n",
    "# MLflow è‡ªå‹•ãƒ­ã‚°æœ‰åŠ¹åŒ–\n",
    "mlflow.langchain.autolog()\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n",
    "\n",
    "# CLIP ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    clip_model = SentenceTransformer('clip-ViT-B-32')\n",
    "\n",
    "print(\"âœ… CLIP ãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c71542e-2bf1-4327-b846-766ddff64766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------#\n",
    "mlflow.langchain.autolog()\n",
    "client = DatabricksFunctionClient()\n",
    "set_uc_function_client(client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41ff41b8-5b8d-413c-a067-2de7a33247f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# ä¿®æ­£ç‰ˆ: Embeddings åŸºåº•ã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ãŸCLIPã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°\n",
    "class CLIPTextEmbeddings(Embeddings):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return [self.model.encode(text).tolist() for text in texts]\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            return self.model.encode(text).tolist()\n",
    "\n",
    "clip_embeddings = CLIPTextEmbeddings(clip_model)\n",
    "\n",
    "# VectorSearchRetrieverTool ã®ä½œæˆ\n",
    "vs_tool = VectorSearchRetrieverTool(\n",
    "    index_name        = INDEX_NAME,\n",
    "    endpoint_name     = VS_ENDPOINT,\n",
    "    embedding         = clip_embeddings,\n",
    "    text_column       = \"image_path\",  # å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    columns           = [\"image_path\"],\n",
    "    num_results       = 5,\n",
    "    tool_name         = f\"fall_detection_image_search_{SUFFIX}\",\n",
    "    tool_description  = (\n",
    "        \"é˜²çŠ¯ã‚«ãƒ¡ãƒ©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã§æ¤œç´¢ã—ã€\"\n",
    "        \"é¡ä¼¼åº¦ã®é«˜ã„ç”»åƒãƒ‘ã‚¹ã‚’è¿”ã—ã¾ã™ã€‚\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"âœ… VectorSearchRetrieverTool ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6204997e-ba8d-4f5e-91ce-4425d3d607c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# ä¿®æ­£ç‰ˆ: text_column ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ \n",
    "try:\n",
    "    vs_tool = VectorSearchRetrieverTool(\n",
    "        index_name        = INDEX_NAME,\n",
    "        endpoint_name     = VS_ENDPOINT,\n",
    "        embedding         = clip_embeddings,\n",
    "        text_column       = \"image_path\",          # â† è¿½åŠ : æ¤œç´¢å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚«ãƒ©ãƒ \n",
    "        columns           = [\"image_path\"],\n",
    "        num_results       = 5,\n",
    "        tool_name         = \"fall_detection_image_search\",\n",
    "        tool_description  = (\n",
    "            \"é˜²çŠ¯ã‚«ãƒ¡ãƒ©ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã§æ¤œç´¢ã—ã€\"\n",
    "            \"é¡ä¼¼åº¦ã®é«˜ã„ç”»åƒãƒ‘ã‚¹ã‚’è¿”ã—ã¾ã™ã€‚\"\n",
    "        ),\n",
    "    )\n",
    "    print(\"âœ… VectorSearchRetrieverTool ãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fd894fc-5559-4016-bdf0-4bcf34ffb630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# å®Œå…¨ä¿®æ­£ç‰ˆ: OpenAIå½¢å¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›å¯¾å¿œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    \"\"\"OpenAIå½¢å¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›ã«å¯¾å¿œã—ãŸ LangGraph ChatAgent\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_graph):\n",
    "        self.agent_graph = agent_graph\n",
    "\n",
    "    def _generate_unique_id(self) -> str:\n",
    "        \"\"\"ä¸€æ„ãª ID ã‚’ç”Ÿæˆ\"\"\"\n",
    "        return str(uuid.uuid4())\n",
    "\n",
    "    def _convert_to_openai_format(self, messages: List[ChatAgentMessage]) -> List[dict]:\n",
    "        \"\"\"ChatAgentMessage ã‚’ OpenAI å½¢å¼ã®è¾æ›¸ã«å¤‰æ›\"\"\"\n",
    "        openai_messages = []\n",
    "        \n",
    "        for msg in messages:\n",
    "            # OpenAI å½¢å¼: {'role': 'user/assistant/system', 'content': '...'}\n",
    "            openai_msg = {\n",
    "                \"role\": msg.role,\n",
    "                \"content\": msg.content or \"\",\n",
    "            }\n",
    "            \n",
    "            # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è¿½åŠ \n",
    "            if msg.name:\n",
    "                openai_msg[\"name\"] = msg.name\n",
    "            if msg.tool_calls:\n",
    "                openai_msg[\"tool_calls\"] = msg.tool_calls\n",
    "            if msg.tool_call_id:\n",
    "                openai_msg[\"tool_call_id\"] = msg.tool_call_id\n",
    "                \n",
    "            openai_messages.append(openai_msg)\n",
    "        \n",
    "        return openai_messages\n",
    "\n",
    "    def _convert_from_langchain_message(self, lc_msg_dict: dict) -> ChatAgentMessage:\n",
    "        \"\"\"LangChain ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¾æ›¸ã‚’ ChatAgentMessage ã«å¤‰æ›\"\"\"\n",
    "        \n",
    "        # LangChain ã® message_to_dict å½¢å¼: {'type': 'human', 'data': {...}}\n",
    "        if 'type' in lc_msg_dict and 'data' in lc_msg_dict:\n",
    "            msg_type = lc_msg_dict['type']\n",
    "            msg_data = lc_msg_dict['data']\n",
    "            \n",
    "            # type ã‚’ role ã«ãƒãƒƒãƒ”ãƒ³ã‚°\n",
    "            role_mapping = {\n",
    "                'human': 'user',\n",
    "                'ai': 'assistant', \n",
    "                'system': 'system',\n",
    "                'tool': 'tool'\n",
    "            }\n",
    "            \n",
    "            role = role_mapping.get(msg_type, 'assistant')\n",
    "            content = msg_data.get('content', '')\n",
    "            \n",
    "            return ChatAgentMessage(\n",
    "                id=msg_data.get('id') or self._generate_unique_id(),\n",
    "                role=role,\n",
    "                content=content,\n",
    "                name=msg_data.get('name'),\n",
    "                tool_calls=msg_data.get('tool_calls'),\n",
    "                tool_call_id=msg_data.get('tool_call_id'),\n",
    "                attachments=msg_data.get('attachments')\n",
    "            )\n",
    "        \n",
    "        # ç›´æ¥çš„ãªè¾æ›¸å½¢å¼ã®å ´åˆ\n",
    "        else:\n",
    "            return ChatAgentMessage(\n",
    "                id=lc_msg_dict.get('id') or self._generate_unique_id(),\n",
    "                role=lc_msg_dict.get('role', 'assistant'),\n",
    "                content=lc_msg_dict.get('content', ''),\n",
    "                name=lc_msg_dict.get('name'),\n",
    "                tool_calls=lc_msg_dict.get('tool_calls'),\n",
    "                tool_call_id=lc_msg_dict.get('tool_call_id'),\n",
    "                attachments=lc_msg_dict.get('attachments')\n",
    "            )\n",
    "\n",
    "    def predict(self, messages: List[ChatAgentMessage], context: ChatContext = None, custom_inputs=None) -> ChatAgentResponse:\n",
    "        \"\"\"ä¿®æ­£ç‰ˆ predict ãƒ¡ã‚½ãƒƒãƒ‰: OpenAIå½¢å¼å¤‰æ›å¯¾å¿œ\"\"\"\n",
    "        try:\n",
    "            # ChatAgentMessage ã‚’ OpenAI å½¢å¼ã«å¤‰æ›\n",
    "            openai_messages = self._convert_to_openai_format(messages)\n",
    "            request = {\"messages\": openai_messages}\n",
    "            \n",
    "            print(f\"ğŸ”„ OpenAIå½¢å¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {json.dumps(openai_messages, ensure_ascii=False, indent=2)}\")\n",
    "            \n",
    "            all_messages = []\n",
    "            for event in self.agent_graph.stream(request, stream_mode=\"updates\"):\n",
    "                print(f\"ğŸ“¨ Event: {event}\")\n",
    "                \n",
    "                for node_name, node_data in event.items():\n",
    "                    if node_data and \"messages\" in node_data:\n",
    "                        for msg_data in node_data[\"messages\"]:\n",
    "                            if msg_data is not None:\n",
    "                                try:\n",
    "                                    # LangChain ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ ChatAgentMessage ã«å¤‰æ›\n",
    "                                    chat_msg = self._convert_from_langchain_message(msg_data)\n",
    "                                    all_messages.append(chat_msg)\n",
    "                                    print(f\"âœ… å¤‰æ›æˆåŠŸ: {chat_msg.role} - {chat_msg.content[:100]}...\")\n",
    "                                except Exception as conv_error:\n",
    "                                    print(f\"âš ï¸ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å¤‰æ›ã‚¨ãƒ©ãƒ¼: {conv_error}\")\n",
    "                                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ\n",
    "                                    fallback_msg = ChatAgentMessage(\n",
    "                                        id=self._generate_unique_id(),\n",
    "                                        role=\"assistant\",\n",
    "                                        content=str(msg_data)\n",
    "                                    )\n",
    "                                    all_messages.append(fallback_msg)\n",
    "            \n",
    "            if not all_messages:\n",
    "                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒä¸€ã¤ã‚‚ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯\n",
    "                fallback_msg = ChatAgentMessage(\n",
    "                    id=self._generate_unique_id(),\n",
    "                    role=\"assistant\",\n",
    "                    content=\"ç”»åƒæ¤œç´¢ãŒå®Œäº†ã—ã¾ã—ãŸãŒã€çµæœã®å–å¾—ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\"\n",
    "                )\n",
    "                all_messages.append(fallback_msg)\n",
    "            \n",
    "            return ChatAgentResponse(messages=all_messages)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”ï¼ˆID ä»˜ãï¼‰\n",
    "            error_message = ChatAgentMessage(\n",
    "                id=self._generate_unique_id(),\n",
    "                role=\"assistant\",\n",
    "                content=f\"ç”»åƒæ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\"\n",
    "            )\n",
    "            return ChatAgentResponse(messages=[error_message])\n",
    "\n",
    "print(\"âœ… LangGraphChatAgent ã‚¯ãƒ©ã‚¹ãŒä½œæˆã•ã‚Œã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1118fda8-d5dc-4c27-b044-8a77a9ae67af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ§‹ç¯‰\n",
    "tools = [vs_tool]\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT)\n",
    "system_prompt = (\n",
    "    \"ã‚ãªãŸã¯é˜²çŠ¯ã‚«ãƒ¡ãƒ©ç”»åƒæ¤œç´¢ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\"\n",
    "    \"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸè‡ªç„¶è¨€èªã‚’ä½¿ã£ã¦ç”»åƒã‚’æ¤œç´¢ã—ã€\"\n",
    "    \"æœ€ã‚‚é–¢é€£ã™ã‚‹ç”»åƒãƒ‘ã‚¹ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚\"\n",
    ")\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Sequence[ToolNode],\n",
    "    system_prompt: Optional[str] = None,\n",
    "):\n",
    "    bound_model = model.bind_tools(tools)\n",
    "\n",
    "    def should_continue(state: ChatAgentState):\n",
    "        last = state[\"messages\"][-1]\n",
    "        return \"continue\" if last.get(\"tool_calls\") else \"end\"\n",
    "\n",
    "    preproc = (\n",
    "        RunnableLambda(lambda s: [{\"role\": \"system\", \"content\": system_prompt}] + s[\"messages\"])\n",
    "        if system_prompt else\n",
    "        RunnableLambda(lambda s: s[\"messages\"])\n",
    "    )\n",
    "    model_runnable = preproc | bound_model\n",
    "\n",
    "    def call_model(state: ChatAgentState, config: RunnableConfig):\n",
    "        resp = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": [resp]}\n",
    "\n",
    "    sg = StateGraph(ChatAgentState)\n",
    "    sg.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    sg.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "    sg.set_entry_point(\"agent\")\n",
    "    sg.add_conditional_edges(\"agent\", should_continue, {\"continue\": \"tools\", \"end\": END})\n",
    "    sg.add_edge(\"tools\", \"agent\")\n",
    "    return sg.compile()\n",
    "\n",
    "# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆ\n",
    "agent_graph = create_tool_calling_agent(llm, tools, system_prompt)\n",
    "AGENT = LangGraphChatAgent(agent_graph)\n",
    "\n",
    "# MLflow ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ãƒ­ã‚°\n",
    "mlflow.models.set_model(AGENT)\n",
    "\n",
    "print(\"âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ­£å¸¸ã«ä½œæˆã•ã‚Œã¾ã—ãŸ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7934581-303e-4190-9d42-be0e2c51fddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# ä¿®æ­£ç‰ˆãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ï¼ˆç”»åƒè¡¨ç¤ºæ©Ÿèƒ½ä»˜ãï¼‰\n",
    "import json\n",
    "import re\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "query_text = \"person lying on the floor\"\n",
    "\n",
    "with mlflow.start_run(run_name=\"image_search_with_display\") as run:\n",
    "    try:\n",
    "        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆï¼ˆID ä»˜ãï¼‰\n",
    "        user_msg = ChatAgentMessage(\n",
    "            id=str(uuid.uuid4()),\n",
    "            role=\"user\",\n",
    "            content=query_text\n",
    "        )\n",
    "        print(f\"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ: ID={user_msg.id}\")\n",
    "        \n",
    "        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—\n",
    "        print(\"ğŸ”„ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—é–‹å§‹...\")\n",
    "        response = AGENT.predict(messages=[user_msg])\n",
    "        \n",
    "        if response and response.messages:\n",
    "            print(f\"âœ… å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(response.messages)}\")\n",
    "            \n",
    "            # æ¤œç´¢çµæœã‹ã‚‰ç”»åƒãƒ‘ã‚¹ã‚’æŠ½å‡º\n",
    "            image_paths = []\n",
    "            \n",
    "            for i, msg in enumerate(response.messages):\n",
    "                print(f\"ğŸ“‹ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{i+1}: ID={msg.id}, Role={msg.role}\")\n",
    "                print(f\"   å†…å®¹: {msg.content[:200]}...\")\n",
    "                \n",
    "                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‹ã‚‰ç”»åƒãƒ‘ã‚¹ã‚’æŠ½å‡º\n",
    "                if msg.role == \"assistant\" and msg.content:\n",
    "                    # JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ¤œç´¢çµæœã‚’è§£æ\n",
    "                    try:\n",
    "                        # JSONã¨ã—ã¦è§£æã‚’è©¦è¡Œ\n",
    "                        if msg.content.strip().startswith('[') or msg.content.strip().startswith('{'):\n",
    "                            parsed_content = json.loads(msg.content)\n",
    "                            if isinstance(parsed_content, list):\n",
    "                                for item in parsed_content:\n",
    "                                    if isinstance(item, dict) and 'image_path' in item:\n",
    "                                        image_paths.append(item['image_path'])\n",
    "                            elif isinstance(parsed_content, dict) and 'image_path' in parsed_content:\n",
    "                                image_paths.append(parsed_content['image_path'])\n",
    "                    except json.JSONDecodeError:\n",
    "                        # JSONè§£æã«å¤±æ•—ã—ãŸå ´åˆã€æ­£è¦è¡¨ç¾ã§ãƒ‘ã‚¹ã‚’æŠ½å‡º\n",
    "                        pass\n",
    "                    \n",
    "                    # æ­£è¦è¡¨ç¾ã§ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŠ½å‡ºï¼ˆ/ã§å§‹ã¾ã‚Š.jpgã§çµ‚ã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰\n",
    "                    path_pattern = r'/[^\\s]*\\.(?:jpg|jpeg|png|gif|bmp)'\n",
    "                    found_paths = re.findall(path_pattern, msg.content, re.IGNORECASE)\n",
    "                    image_paths.extend(found_paths)\n",
    "                    \n",
    "                    # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒœãƒªãƒ¥ãƒ¼ãƒ å†…ã®ãƒ‘ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚æ¤œç´¢\n",
    "                    frame_vol_pattern = r'/Volumes/[^\\s]*\\.(?:jpg|jpeg|png|gif|bmp)'\n",
    "                    frame_paths = re.findall(frame_vol_pattern, msg.content, re.IGNORECASE)\n",
    "                    image_paths.extend(frame_paths)\n",
    "            \n",
    "            # é‡è¤‡ã‚’é™¤å»\n",
    "            image_paths = list(set(image_paths))\n",
    "            \n",
    "            assistant = response.messages[-1]\n",
    "            \n",
    "            # MLflow ãƒ­ã‚°\n",
    "            mlflow.log_param(\"query_text\", query_text)\n",
    "            mlflow.log_param(\"response_status\", \"success\")\n",
    "            mlflow.log_param(\"agent_response\", assistant.content)\n",
    "            mlflow.log_param(\"message_count\", len(response.messages))\n",
    "            mlflow.log_param(\"embedding_model\", \"clip-ViT-B-32\")\n",
    "            mlflow.log_param(\"found_image_count\", len(image_paths))\n",
    "            mlflow.log_param(\"image_paths\", \";\".join(image_paths))\n",
    "            \n",
    "            # æ¤œç´¢çµæœã®ç”»åƒã‚’ã™ã¹ã¦è¡¨ç¤º\n",
    "            print(f\"\\nğŸ–¼ï¸ æ¤œç´¢ã•ã‚ŒãŸç”»åƒæ•°: {len(image_paths)}\")\n",
    "            \n",
    "            if image_paths:\n",
    "                for idx, img_path in enumerate(image_paths, 1):\n",
    "                    try:\n",
    "                        if os.path.exists(img_path):\n",
    "                            print(f\"\\nğŸ“· ç”»åƒ {idx}: {img_path}\")\n",
    "                            \n",
    "                            # ç”»åƒã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è¡¨ç¤º\n",
    "                            img = Image.open(img_path)\n",
    "                            \n",
    "                            # ç”»åƒã®ã‚µã‚¤ã‚ºæƒ…å ±ã‚’è¡¨ç¤º\n",
    "                            print(f\"   ã‚µã‚¤ã‚º: {img.size[0]} x {img.size[1]} ãƒ”ã‚¯ã‚»ãƒ«\")\n",
    "                            \n",
    "                            # Databricks ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«ç”»åƒã‚’è¡¨ç¤º\n",
    "                            display(img)\n",
    "                            \n",
    "                            # ã‚µãƒ ãƒã‚¤ãƒ«ä½œæˆï¼ˆMLflowç”¨ï¼‰\n",
    "                            thumbnail = img.copy()\n",
    "                            thumbnail.thumbnail((300, 300))  # 300x300ã®ã‚µãƒ ãƒã‚¤ãƒ«\n",
    "                            \n",
    "                            # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ä¿å­˜\n",
    "                            thumb_filename = f\"thumbnail_{idx}_{os.path.basename(img_path)}\"\n",
    "                            thumb_path = os.path.join(\"/tmp\", thumb_filename)\n",
    "                            thumbnail.save(thumb_path)\n",
    "                            \n",
    "                            # MLflowã«ã‚µãƒ ãƒã‚¤ãƒ«ã‚’ãƒ­ã‚°\n",
    "                            mlflow.log_artifact(thumb_path, artifact_path=\"search_result_thumbnails\")\n",
    "                            \n",
    "                        else:\n",
    "                            print(f\"âš ï¸ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {img_path}\")\n",
    "                            \n",
    "                    except Exception as img_error:\n",
    "                        print(f\"âŒ ç”»åƒè¡¨ç¤ºã‚¨ãƒ©ãƒ¼ ({img_path}): {str(img_error)}\")\n",
    "                \n",
    "                # ç”»åƒä¸€è¦§ã‚’Markdownå½¢å¼ã§ã‚‚è¡¨ç¤º\n",
    "                print(\"\\n## æ¤œç´¢çµæœç”»åƒä¸€è¦§\")\n",
    "                for idx, img_path in enumerate(image_paths, 1):\n",
    "                    print(f\"{idx}. `{img_path}`\")\n",
    "                    \n",
    "            else:\n",
    "                print(\"âŒ æ¤œç´¢çµæœã«ç”»åƒãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "                print(\"ãƒ‡ãƒãƒƒã‚°ç”¨: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç­”å†…å®¹:\")\n",
    "                for msg in response.messages:\n",
    "                    print(f\"  - {msg.role}: {msg.content}\")\n",
    "            \n",
    "            print(f\"\\nâœ… MLflow run: {mlflow.get_artifact_uri()}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "            mlflow.log_param(\"response_status\", \"no_response\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}\")\n",
    "        mlflow.log_param(\"error_message\", str(e))\n",
    "        mlflow.log_param(\"response_status\", \"error\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "create_agent_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
